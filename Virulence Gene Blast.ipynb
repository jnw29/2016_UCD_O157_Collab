{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libraries needed for extraction and for formatting spreadsheet\n",
    "\n",
    "import os\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio.Blast.Applications import NcbiblastnCommandline\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import xml.etree.ElementTree as ET\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Color, PatternFill, Style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Blasts all files in './VGDB' against the genomes.\n",
    "#Genomes have the simplified name S## where ## are integers\n",
    "#Creates a tempororary infile for the query, then deletes it.\n",
    "#Switching to allow more processing in the future of the in-sequence (format changes)\n",
    "#Output - xml files (outfmt=5) to './VG_BLAST_Hits/'\n",
    "#folders must be made in advance if not already existing.\n",
    "\n",
    "q = './VGDB/tempfile.fasta'\n",
    "d = './BLAST_DB/DavisDB.fasta'\n",
    "\n",
    "for file in os.listdir('./VGDB'):\n",
    "    if file.endswith('.fa'):\n",
    "        for item in SeqIO.parse('./VGDB/'+file,'fasta'):\n",
    "            otf = open(q,'w')\n",
    "            SeqIO.write(item, q, 'fasta')\n",
    "            otf.close\n",
    "            o = './VG_BLAST_HITS/'+os.path.split(file)[1].split('.')[0]+'.xml'\n",
    "            os.system(str(NcbiblastnCommandline(query = q, db = d, out = o, outfmt=5)))\n",
    "os.remove(q)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract BLAST hits\n",
    "\n",
    "#hitdict is a dictionary of all blast hits.\n",
    "#it stores a list of important data for each hit for calculation.\n",
    "#hits are checked to be one per contig at end.\n",
    "#hitdict list order:\n",
    "#query start, query stop, query length, alignment length,\n",
    "#number of identical positions, number of 'positive' positions\n",
    "#number of gaps.\n",
    "#[qstart,qstop,qlen,alen,ids,pos,gaps]\n",
    "\n",
    "hitdict = {}\n",
    "\n",
    "#retrieves xml file, parses with element tree, root = top node\n",
    "for file in os.listdir('./VG_BLAST_HITS'):\n",
    "    if file.endswith('.xml'):\n",
    "        queryg = os.path.splitext(file)[0]\n",
    "        queryf = os.path.join('./VG_BLAST_HITS/'+file)\n",
    "        tree = ET.parse(queryf)\n",
    "        root = tree.getroot()\n",
    "\n",
    "#Iteration - query information\n",
    "#hit- hits within genome\n",
    "#hsp- alignment infor within a hit\n",
    "        for iteration in root.findall(\".//Iteration\"):\n",
    "            qlen = iteration.find('Iteration_query-len').text\n",
    "        for hit in root.findall(\".//Hit\"):\n",
    "            contig = hit.find('Hit_id').text\n",
    "            for hsp in hit.findall('.//Hit_hsps/Hsp'):\n",
    "                hseq = hsp.find('Hsp_hseq').text\n",
    "                qstart = hsp.find('Hsp_query-from').text\n",
    "                qstop = hsp.find('Hsp_query-to').text\n",
    "                hstart = hsp.find('Hsp_hit-from').text\n",
    "                hstop = hsp.find('Hsp_hit-to').text\n",
    "                alen = hsp.find('Hsp_align-len').text\n",
    "                ids = hsp.find('Hsp_identity').text\n",
    "                pos = hsp.find('Hsp_positive').text\n",
    "                gaps = hsp.find('Hsp_gaps').text\n",
    "                \n",
    "            key = contig+'|'+queryg\n",
    "            keylist = [item for item in hitdict.keys()]\n",
    "            if key in keylist:\n",
    "                print('overwrite at '+key)\n",
    "                \n",
    "            hitdict[key]=[qstart,qstop,qlen,alen,ids,pos,gaps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-db247beb6c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorkbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mws1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mws2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mws3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mws4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/openpyxl/workbook/workbook.py\u001b[0m in \u001b[0;36mcreate_sheet\u001b[0;34m(self, title, index)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mnew_ws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWriteOnlyWorksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_workbook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mnew_ws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_ws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/openpyxl/worksheet/worksheet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, title)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWorksheet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_dimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBoundDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         self.column_dimensions = DimensionHolder(worksheet=self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/openpyxl/workbook/child.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, title)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/openpyxl/workbook/child.py\u001b[0m in \u001b[0;36mtitle\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     78\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Worksheet titles must be unicode\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINVALID_TITLE_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid character {0} found in sheet title\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "#Create lists of all genomes and genes - used to index information by item name!\n",
    "\n",
    "#output is an excel file with releavant information\n",
    "wb = Workbook()\n",
    "ws1 = wb.create_sheet(0)\n",
    "ws2 = wb.create_sheet(1)\n",
    "ws3 = wb.create_sheet(2)\n",
    "ws4 = wb.create_sheet(3)\n",
    "ws5 = wb.create_sheet(4)\n",
    "ws1.title = 'hit locations'\n",
    "ws2.title = 'hit count'\n",
    "ws3.title = '%ID, hit len, hit range'\n",
    "ws4.title = '%ID, %POS, Gaps%'\n",
    "ws5.title = 'total query coverage & gaps'\n",
    "gn = ['0','1',]\n",
    "hn = ['0','1',]\n",
    "keys = hitdict.keys()\n",
    "\n",
    "#Flipped.\n",
    "for item in keys:\n",
    "    hn.append(item.split('|')[0].split('(')[0])\n",
    "    gn.append(item.split('|')[1])\n",
    "    \n",
    "#Set function removes duplicates, list makes it a list, sorted sorts the list\n",
    "gn = sorted(list(set(gn)))\n",
    "hn = sorted(list(set(hn)))\n",
    "\n",
    "#Labels, labels in the first row and column are important...\n",
    "for n in range(2, len(gn)):\n",
    "    ws1.cell(row = n, column = 1).value = gn[n]\n",
    "    ws2.cell(row = n, column = 1).value = gn[n]\n",
    "    ws3.cell(row = n, column = 1).value = gn[n]\n",
    "    ws4.cell(row = n, column = 1).value = gn[n]\n",
    "    ws5.cell(row = n, column = 1).value = gn[n]\n",
    "for n in range(2, len(hn)):\n",
    "    ws1.cell(row = 1, column = n).value = hn[n]\n",
    "    ws2.cell(row = 1, column = n).value = hn[n]\n",
    "    ws3.cell(row = 1, column = n).value = hn[n]\n",
    "    ws4.cell(row = 1, column = n).value = hn[n]\n",
    "    ws5.cell(row = 1, column = n).value = hn[n]\n",
    "    \n",
    "#makes the file\n",
    "#example dict: S87(NODE_65)|EH250_2b_A\n",
    "\n",
    "for item in hitdict:\n",
    "    genome = item.split('(')[0]\n",
    "    contig = item.split('(')[1].split(')')[0]\n",
    "    gene = item.split('|')[1]\n",
    "    ids = hitdict[item][4]\n",
    "    pos = hitdict[item][5]\n",
    "    gaps = hitdict[item][6]\n",
    "    qlen = hitdict[item][2]\n",
    "    alen = hitdict[item][3]\n",
    "    qstart=hitdict[item][0]\n",
    "    qstop=hitdict[item][1]\n",
    "    hi = hn.index(genome)\n",
    "    gi = gn.index(gene)\n",
    "    \n",
    "    old=ws1.cell(row = gi, column = hi).value\n",
    "    if old is None:\n",
    "        old = ''\n",
    "    ws1.cell(row = gi, column = hi).value = old+','+item.split('|')[0]\n",
    "    if ws1.cell(row = gi, column = hi).value.startswith(','):\n",
    "        ws1.cell(row = gi, column = hi).value = ws1.cell(row = gi, column = hi).value[1:]\n",
    "    \n",
    "    old = ws3.cell(row = gi, column = hi).value\n",
    "    if old is None:\n",
    "        old = ''\n",
    "    ws3.cell(row = gi, column = hi).value = old+' || '+'ID: '+item.split('|')[0]+', {0:.2f}'.format(int(ids)*100/int(alen))+qlen+'%ID, Query len: '+qlen+' Aln len: '+alen+', range: '+qstart+'-'+qstop\n",
    "    \n",
    "    old = ws4.cell(row = gi, column = hi).value\n",
    "    if old is None:\n",
    "        old = ''\n",
    "    ws4.cell(row = gi, column = hi).value = old+' || '+'{0:.2f}'.format(int(ids)/int(alen))+', '+'{0:.2f}'.format(int(pos)/int(qlen))+', '+'{0:.2f}'.format(int(gaps)/int(qlen))\n",
    "\n",
    "for gi in range(2, len(gn)):\n",
    "    for hi in range(2,len(hn)):\n",
    "        if ws1.cell(row = (gi), column = (hi)).value is not (None):\n",
    "            ws2.cell(row = (gi), column = (hi)).value = len(ws1.cell(row = (gi), column = (hi)).value.split(','))\n",
    "        #calculator for putting together stitches\n",
    "            \n",
    "wb.save('VG_gene_locations_WpSS17.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EDL933_eae', 'EDL933_espB', 'EDL933_espF', 'EDL933_tir', 'EDL933_vgrG', 'SS17_1721', 'SS17_2051', 'SS17_2052', 'SS17_3604', 'SS17_4737', 'SS17_7017', 'SS17_7023', 'SS17_espD', 'SS17_espG', 'SS17_espH', 'SS17_espJ', 'SS17_espL1', 'SS17_espM2', 'SS17_espN', 'SS17_espP', 'SS17_espR1', 'SS17_espW', 'SS17_espX1', 'SS17_espX4', 'SS17_espX5', 'SS17_espX6', 'SS17_espX7', 'SS17_espY1', 'SS17_espZ', 'SS17_katP', 'SS17_nleA', 'SS17_nleB1', 'SS17_nleB2', 'SS17_nleC', 'SS17_nleD', 'SS17_nleE', 'SS17_nleF', 'SS17_nleG', 'SS17_nleG7', 'SS17_nleH1', 'SS17_nleH2', 'SS17_toxB', 'Sakai_hlyoperon', 'Sakai_stcE', 'pSS17']\n",
      "['S01', 'S02', 'S03', 'S04', 'S05', 'S06', 'S07', 'S08', 'S09', 'S10', 'S11', 'S12', 'S13', 'S14', 'S15', 'S16', 'S18', 'S19', 'S20', 'S21', 'S22', 'S23', 'S24', 'S25', 'S26', 'S27', 'S28', 'S29', 'S30', 'S31', 'S32', 'S33', 'S34', 'S35', 'S36', 'S37', 'S38', 'S39', 'S40', 'S41', 'S42', 'S43', 'S44', 'S45', 'S46', 'S47', 'S48', 'S49', 'S50', 'S51', 'S52', 'S53', 'S55', 'S56', 'S57', 'S58', 'S59', 'S60', 'S61', 'S62', 'S63', 'S64', 'S65', 'S66', 'S67', 'S68', 'S69', 'S70', 'S71', 'S72', 'S73', 'S74', 'S75', 'S76', 'S77', 'S78', 'S79', 'S80', 'S81', 'S82', 'S83', 'S84', 'S85', 'S86', 'S87', 'S88']\n"
     ]
    }
   ],
   "source": [
    "#Create a table for in-text presentation\n",
    "#Must run the hitdict creator first (two cells up)\n",
    "\n",
    "wb = Workbook()\n",
    "ws1 = wb.create_sheet(0)\n",
    "ws1.title = 'In Text Figure'\n",
    "\n",
    "fillyes = PatternFill(fill_type='solid', start_color='0000FF', end_color='0000FF')\n",
    "fillno = PatternFill(fill_type='solid', start_color='CCCCCC', end_color='CCCCCC')\n",
    "\n",
    "\n",
    "#Retrieve keys from hitdict for creating lists of genes and \n",
    "keys = hitdict.keys()\n",
    "\n",
    "hn=[]\n",
    "gn=[]\n",
    "for item in keys:\n",
    "    hn.append(item.split('|')[0].split('(')[0])\n",
    "    gn.append(item.split('|')[1])\n",
    "    \n",
    "#Create sorted sets of the genes here.\n",
    "gn = sorted(set(gn))\n",
    "hn = sorted(set(hn))\n",
    "\n",
    "#Exclude lists: lists of things that should be excluded from the table\n",
    "#gnx - genes to exclude\n",
    "#hnx - genomes (hits) to exclude\n",
    "\n",
    "#S54 - Low quality.\n",
    "#S17 - Returns very fragmented blast hits. Unknown reason - other quality metrics look fine\n",
    "\n",
    "gnx = ['EDL933_etpoperonpartialhlyC','Sakai_hlyA', 'Sakai_hlyB', 'Sakai_hlyC', 'Sakai_hlyD', 'pO157_ecf1', 'pO157_ecf1to4partial4', 'pO157_ecf2']\n",
    "hnx = ['S54', 'S17']\n",
    "for item in gnx:\n",
    "    gn.remove(item)\n",
    "for item in hnx:\n",
    "    hn.remove(item)\n",
    "print(gn)\n",
    "print(hn)\n",
    "\n",
    "#Label columns and rows\n",
    "for n in range(len(hn)):\n",
    "    ws1.cell(row = n+2, column = 1).value = hn[n]\n",
    "for n in range(len(gn)):\n",
    "    ws1.cell(row = 1, column = n+2).value = gn[n]\n",
    "\n",
    "#hitdict[key]=[qstart,qstop,qlen,alen,ids,pos,gaps]    \n",
    "tempgn = []\n",
    "temphn = []\n",
    "for hit in hn:\n",
    "    for gene in gn:\n",
    "        hitps=[]\n",
    "        for item in hitdict:\n",
    "            if (gene in item) and (hit in item):\n",
    "                #if %ID < 90%, ignore. O157 is very homogenous, high ID cutoff\n",
    "                if (int(hitdict[item][4])/int(hitdict[item][3]))<.95:\n",
    "                    continue\n",
    "                qlen = int(hitdict[item][2])\n",
    "                hitps.append((int(hitdict[item][0]),int(hitdict[item][1])))\n",
    "        hitpss = sorted(hitps, key = lambda x: x[0])\n",
    "        for i in range(1, len(hitpss)):\n",
    "            if hitpss[i][0]<hitpss[i-1][1]:\n",
    "                hitpss[i]=(hitpss[i-1][0],hitpss[i][1])\n",
    "                hitpss[i-1]=(0,0)\n",
    "                continue\n",
    "        if (0,0) in hitpss:\n",
    "            for i in range(hitpss.count((0,0))):\n",
    "                hitpss.remove((0,0))\n",
    "\n",
    "        for i in range(1, len(hitpss)):\n",
    "            if hitpss[i][0]<hitpss[i-1][1]:\n",
    "                print('Incomplete trimming')\n",
    "                continue\n",
    "\n",
    "        lens = [(i[1]-i[0]+1) for i in hitpss]\n",
    "        slens = sum(lens)\n",
    "        if (slens/qlen) >= 0.6:\n",
    "            ws1.cell(row = hn.index(hit)+2, column = gn.index(gene)+2).fill = fillyes\n",
    "        else:\n",
    "            ws1.cell(row = hn.index(hit)+2, column = gn.index(gene)+2).fill = fillno\n",
    "\n",
    "wb.save('VG_gene_in-text_WpSS17.xlsx')            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set check OK\n",
      "['EDL933_eae', 'EDL933_espB', 'EDL933_espF', 'EDL933_tir', 'EDL933_vgrG', 'SS17_1721', 'SS17_2051', 'SS17_2052', 'SS17_3604', 'SS17_4737', 'SS17_7017', 'SS17_7023', 'SS17_espD', 'SS17_espG', 'SS17_espH', 'SS17_espJ', 'SS17_espL1', 'SS17_espM2', 'SS17_espN', 'SS17_espP', 'SS17_espR1', 'SS17_espW', 'SS17_espX1', 'SS17_espX4', 'SS17_espX5', 'SS17_espX6', 'SS17_espX7', 'SS17_espY1', 'SS17_espZ', 'SS17_katP', 'SS17_nleA', 'SS17_nleB1', 'SS17_nleB2', 'SS17_nleC', 'SS17_nleD', 'SS17_nleE', 'SS17_nleF', 'SS17_nleG', 'SS17_nleG7', 'SS17_nleH1', 'SS17_nleH2', 'SS17_toxB', 'Sakai_hlyoperon', 'Sakai_stcE']\n",
      "['S36', 'S35', 'S88', 'S83', 'S82', 'S84', 'S73', 'S58', 'S61', 'S60', 'S57', 'S42', 'S80', 'S79', 'S48', 'S43', 'S62', 'S52', 'S53', 'S47', 'S63', 'S59', 'S44', 'S65', 'S64', 'S50', 'S51', 'S72', 'S56', 'S46', 'S49', 'S45', 'S55', 'S76', 'S75', 'S38', 'S39', 'S77', 'S78', 'S81', 'S41', 'S40', 'S87', 'S71', 'S68', 'S67', 'S15', 'S13', 'S16', 'S05', 'S20', 'S74', 'S27', 'S22', 'S06', 'S86', 'S85', 'S12', 'S37', 'S07', 'S14', 'S34', 'S01', 'S31', 'S10', 'S23', 'S02', 'S21', 'S32', 'S26', 'S29', 'S03', 'S19', 'S30', 'S18', 'S24', 'S25', 'S28', 'S11', 'S04', 'S08', 'S33', 'S09']\n"
     ]
    }
   ],
   "source": [
    "#REORDERED GENOME LIST TO MATCH PHYLOGENETIC TREE IN FIGURE\n",
    "\n",
    "#Create a table for in-text presentation\n",
    "#Must run the hitdict creator first (two cells up)\n",
    "\n",
    "wb = Workbook()\n",
    "ws1 = wb.create_sheet(0)\n",
    "ws1.title = 'In Text Figure'\n",
    "\n",
    "fillyes = PatternFill(fill_type='solid', start_color='0000FF', end_color='0000FF')\n",
    "fillno = PatternFill(fill_type='solid', start_color='CCCCCC', end_color='CCCCCC')\n",
    "\n",
    "\n",
    "#Retrieve keys from hitdict for creating lists of genes and \n",
    "keys = hitdict.keys()\n",
    "\n",
    "hn=[]\n",
    "gn=[]\n",
    "for item in keys:\n",
    "    hn.append(item.split('|')[0].split('(')[0])\n",
    "    gn.append(item.split('|')[1])\n",
    "    \n",
    "#Create sorted sets of the genes here.\n",
    "gn = sorted(set(gn))\n",
    "hn = sorted(set(hn))\n",
    "\n",
    "#Exclude lists: lists of things that should be excluded from the table\n",
    "#gnx - genes to exclude\n",
    "#hnx - genomes (hits) to exclude\n",
    "\n",
    "#S54 - Low quality.\n",
    "#S17 - Returns very fragmented blast hits. Unknown reason - other quality metrics look fine\n",
    "\n",
    "gnx = ['pSS17','EDL933_etpoperonpartialhlyC','Sakai_hlyA', 'Sakai_hlyB', 'Sakai_hlyC', 'Sakai_hlyD', 'pO157_ecf1', 'pO157_ecf1to4partial4', 'pO157_ecf2']\n",
    "hnx = ['S54', 'S17','S66','S69','S70']\n",
    "for item in gnx:\n",
    "    gn.remove(item)\n",
    "for item in hnx:\n",
    "    hn.remove(item)\n",
    "\n",
    "hnorder=['S36','S35','S88','S83','S82','S84','S73','S58','S61','S60','S57','S42','S80','S79','S48',\n",
    "        'S43','S62','S52','S53','S47','S63','S59','S44','S65','S64',\n",
    "        'S50','S51','S72','S56','S46','S49','S45','S55','S76','S75','S38','S39','S77','S78','S81','S41',\n",
    "        'S40','S87','S71','S68','S67','S15','S13','S16','S05','S20',\n",
    "        'S74','S27','S22','S06','S86','S85','S12','S37','S07','S14','S34','S01','S31','S10','S23',\n",
    "        'S02','S21','S32','S26','S29','S03','S19','S30','S18','S24',\n",
    "        'S25','S28','S11','S04','S08','S33','S09']\n",
    "if sorted(set(hn)) == sorted(set(hnorder)):\n",
    "    print('set check OK')\n",
    "    hn = hnorder\n",
    "for item in hn:\n",
    "    if item not in hnorder:\n",
    "        print(item)\n",
    "\n",
    "print(gn)\n",
    "print(hn)\n",
    "\n",
    "#Label columns and rows\n",
    "for n in range(len(hn)):\n",
    "    ws1.cell(row = n+2, column = 1).value = hn[n]\n",
    "for n in range(len(gn)):\n",
    "    ws1.cell(row = 1, column = n+2).value = gn[n]\n",
    "\n",
    "#hitdict[key]=[qstart,qstop,qlen,alen,ids,pos,gaps]    \n",
    "tempgn = []\n",
    "temphn = []\n",
    "for hit in hn:\n",
    "    for gene in gn:\n",
    "        hitps=[]\n",
    "        for item in hitdict:\n",
    "            if (gene in item) and (hit in item):\n",
    "                #if %ID < 90%, ignore. O157 is very homogenous, high ID cutoff\n",
    "                if (int(hitdict[item][4])/int(hitdict[item][3]))<.95:\n",
    "                    continue\n",
    "                qlen = int(hitdict[item][2])\n",
    "                hitps.append((int(hitdict[item][0]),int(hitdict[item][1])))\n",
    "        hitpss = sorted(hitps, key = lambda x: x[0])\n",
    "        for i in range(1, len(hitpss)):\n",
    "            if hitpss[i][0]<hitpss[i-1][1]:\n",
    "                hitpss[i]=(hitpss[i-1][0],hitpss[i][1])\n",
    "                hitpss[i-1]=(0,0)\n",
    "                continue\n",
    "        if (0,0) in hitpss:\n",
    "            for i in range(hitpss.count((0,0))):\n",
    "                hitpss.remove((0,0))\n",
    "\n",
    "        for i in range(1, len(hitpss)):\n",
    "            if hitpss[i][0]<hitpss[i-1][1]:\n",
    "                print('Incomplete trimming')\n",
    "                continue\n",
    "\n",
    "        lens = [(i[1]-i[0]+1) for i in hitpss]\n",
    "        slens = sum(lens)\n",
    "        if (slens/qlen) >= 0.6:\n",
    "            ws1.cell(row = hn.index(hit)+2, column = gn.index(gene)+2).fill = fillyes\n",
    "        else:\n",
    "            ws1.cell(row = hn.index(hit)+2, column = gn.index(gene)+2).fill = fillno\n",
    "        if gene == 'pSS17':\n",
    "            ws1.cell(row = hn.index(hit)+2, column = gn.index(gene)+2).value = (slens/qlen)\n",
    "            \n",
    "\n",
    "wb.save('VG_gene_in-text_reordered2phylo_WpSS17.xlsx')            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temphns = sorted(set(temphn))\n",
    "tempgns = sorted(set(tempgn))\n",
    "for hit in temphns:\n",
    "    print(hit, temphn.count(hit))\n",
    "for gene in tempgns:\n",
    "    print(gene, tempgn.count(gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ws3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f051993279d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mws3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mhits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mws3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mqlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Query len: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' Aln'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ws3' is not defined"
     ]
    }
   ],
   "source": [
    "fill1= PatternFill(fill_type='solid', start_color='FF9999', end_color='FF9999')\n",
    "fill2= PatternFill(fill_type='solid', start_color='BB0000', end_color='BB0000')\n",
    "for gi in range(2, len(gn)):\n",
    "    for hi in range(2,len(hn)):\n",
    "        if ws3.cell(row = (gi), column = (hi)).value is not None:\n",
    "            hits = ws3.cell(row = (gi), column = (hi)).value\n",
    "            qlen = hits.split('Query len: ')[1].split(' Aln')[0]\n",
    "            ranges = hits.split('range: ')\n",
    "            ranges = [thing.split(' ||')[0] for thing in ranges][1:]\n",
    "            ranges = [(int(thing.split('-')[0]), int(thing.split('-')[1])) for thing in ranges]\n",
    "            ranges = sorted(ranges, key=lambda lam: lam[0])\n",
    "            if len(ranges) > 1:\n",
    "                for i in range(1,len(ranges)):\n",
    "                    if (ranges[i][0] <= ranges[i-1][1]) and (ranges[i][1] > ranges[i-1][1]):\n",
    "                        ranges[i-1] = (ranges[i-1][0],ranges[i][1])\n",
    "                        ranges[i] = (0,0)\n",
    "                        ranges = sorted(ranges, key=lambda lam: lam[0])\n",
    "                    if (ranges[i][0] <= ranges[i-1][1]) and (ranges[i][1] <= ranges[i-1][1]):\n",
    "                        ranges[i] = (0,0)\n",
    "                        ranges = sorted(ranges, key=lambda lam: lam[0])\n",
    "            ranges = [thing for thing in ranges if thing != (0,0)]\n",
    "            totcoverage = [thing[1]-thing[0] for thing in ranges]\n",
    "            totcoverage = sum(totcoverage)\n",
    "            ranges = [str(thing[0])+'-'+str(thing[1]) for thing in ranges]\n",
    "            rangesstring = ', '.join(ranges)\n",
    "            ws5.cell(row = (gi), column = (hi)).value = rangesstring+' ('+str(len(ranges)-1)+' gaps, '+str(totcoverage)+' of '+qlen+' bases)'\n",
    "            if len(ranges) > 1:\n",
    "                ws5.cell(row = (gi), column = (hi)).fill = fill1\n",
    "        if ws5.cell(row = (gi), column = (hi)).value is None:\n",
    "            ws5.cell(row = (gi), column = (hi)).fill = fill2\n",
    "wb.save('VG_gene_locations_WpSS17.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Blasts all ORFS in './VGDB/pSS17' against the genomes.\n",
    "#Genomes have the simplified name S## where ## are integers\n",
    "#Creates a tempororary infile for the query, then deletes it.\n",
    "#Switching to allow more processing in the future of the in-sequence (format changes)\n",
    "#Output - xml files (outfmt=5) to './VG_BLAST_Hits/'\n",
    "#folders must be made in advance if not already existing.\n",
    "\n",
    "q = './VGDB/tempfile.fasta'\n",
    "d = './BLAST_DB/DavisDB.fasta'\n",
    "\n",
    "for item in SeqIO.parse('./VGDB/pSS17.fa','fasta'):\n",
    "        otf = open(q,'w')\n",
    "        SeqIO.write(item, q, 'fasta')\n",
    "        otf.close\n",
    "        o = './VG_BLAST_HITS/'+os.path.split(file)[1].split('.')[0]+'.xml'\n",
    "        os.system(str(NcbiblastnCommandline(query = q, db = d, out = o, outfmt=5)))\n",
    "os.remove(q)\n",
    "\n",
    "#Extract BLAST hits\n",
    "\n",
    "#hitdict is a dictionary of all blast hits.\n",
    "#it stores a list of important data for each hit for calculation.\n",
    "#hits are checked to be one per contig at end.\n",
    "#hitdict list order:\n",
    "#query start, query stop, query length, alignment length,\n",
    "#number of identical positions, number of 'positive' positions\n",
    "#number of gaps.\n",
    "#[qstart,qstop,qlen,alen,ids,pos,gaps]\n",
    "\n",
    "hitdict = {}\n",
    "\n",
    "#retrieves xml file, parses with element tree, root = top node\n",
    "for file in os.listdir('./VG_BLAST_HITS'):\n",
    "    if file.endswith('.xml'):\n",
    "        queryg = os.path.splitext(file)[0]\n",
    "        queryf = os.path.join('./VG_BLAST_HITS/'+file)\n",
    "        tree = ET.parse(queryf)\n",
    "        root = tree.getroot()\n",
    "\n",
    "#Iteration - query information\n",
    "#hit- hits within genome\n",
    "#hsp- alignment infor within a hit\n",
    "        for iteration in root.findall(\".//Iteration\"):\n",
    "            qlen = iteration.find('Iteration_query-len').text\n",
    "        for hit in root.findall(\".//Hit\"):\n",
    "            contig = hit.find('Hit_id').text\n",
    "            for hsp in hit.findall('.//Hit_hsps/Hsp'):\n",
    "                hseq = hsp.find('Hsp_hseq').text\n",
    "                qstart = hsp.find('Hsp_query-from').text\n",
    "                qstop = hsp.find('Hsp_query-to').text\n",
    "                hstart = hsp.find('Hsp_hit-from').text\n",
    "                hstop = hsp.find('Hsp_hit-to').text\n",
    "                alen = hsp.find('Hsp_align-len').text\n",
    "                ids = hsp.find('Hsp_identity').text\n",
    "                pos = hsp.find('Hsp_positive').text\n",
    "                gaps = hsp.find('Hsp_gaps').text\n",
    "                \n",
    "            key = contig+'|'+queryg\n",
    "            keylist = [item for item in hitdict.keys()]\n",
    "            if key in keylist:\n",
    "                print('overwrite at '+key)\n",
    "                \n",
    "            hitdict[key]=[qstart,qstop,qlen,alen,ids,pos,gaps]\n",
    "     \n",
    "\n",
    "#REORDERED GENOME LIST TO MATCH PHYLOGENETIC TREE IN FIGURE\n",
    "\n",
    "#Create a table for in-text presentation\n",
    "#Must run the hitdict creator first (two cells up)\n",
    "\n",
    "wb = Workbook()\n",
    "ws1 = wb.create_sheet(0)\n",
    "ws1.title = 'In Text Figure'\n",
    "\n",
    "fillyes = PatternFill(fill_type='solid', start_color='0000FF', end_color='0000FF')\n",
    "fillno = PatternFill(fill_type='solid', start_color='CCCCCC', end_color='CCCCCC')\n",
    "\n",
    "\n",
    "#Retrieve keys from hitdict for creating lists of genes and \n",
    "keys = hitdict.keys()\n",
    "\n",
    "hn=[]\n",
    "gn=[]\n",
    "for item in keys:\n",
    "    hn.append(item.split('|')[0].split('(')[0])\n",
    "    gn.append(item.split('|')[1])\n",
    "    \n",
    "#Create sorted sets of the genes here.\n",
    "gn = sorted(set(gn))\n",
    "hn = sorted(set(hn))\n",
    "\n",
    "#Exclude lists: lists of things that should be excluded from the table\n",
    "#gnx - genes to exclude\n",
    "#hnx - genomes (hits) to exclude\n",
    "\n",
    "#S54 - Low quality.\n",
    "#S17 - Returns very fragmented blast hits. Unknown reason - other quality metrics look fine\n",
    "\n",
    "gnx = ['pSS17','EDL933_etpoperonpartialhlyC','Sakai_hlyA', 'Sakai_hlyB', 'Sakai_hlyC', 'Sakai_hlyD', 'pO157_ecf1', 'pO157_ecf1to4partial4', 'pO157_ecf2']\n",
    "hnx = ['S54', 'S17','S66','S69','S70']\n",
    "for item in gnx:\n",
    "    gn.remove(item)\n",
    "for item in hnx:\n",
    "    hn.remove(item)\n",
    "\n",
    "hnorder=['S36','S35','S88','S83','S82','S84','S73','S58','S61','S60','S57','S42','S80','S79','S48',\n",
    "        'S43','S62','S52','S53','S47','S63','S59','S44','S65','S64',\n",
    "        'S50','S51','S72','S56','S46','S49','S45','S55','S76','S75','S38','S39','S77','S78','S81','S41',\n",
    "        'S40','S87','S71','S68','S67','S15','S13','S16','S05','S20',\n",
    "        'S74','S27','S22','S06','S86','S85','S12','S37','S07','S14','S34','S01','S31','S10','S23',\n",
    "        'S02','S21','S32','S26','S29','S03','S19','S30','S18','S24',\n",
    "        'S25','S28','S11','S04','S08','S33','S09']\n",
    "if sorted(set(hn)) == sorted(set(hnorder)):\n",
    "    print('set check OK')\n",
    "    hn = hnorder\n",
    "for item in hn:\n",
    "    if item not in hnorder:\n",
    "        print(item)\n",
    "\n",
    "print(gn)\n",
    "print(hn)\n",
    "\n",
    "#Label columns and rows\n",
    "for n in range(len(hn)):\n",
    "    ws1.cell(row = n+2, column = 1).value = hn[n]\n",
    "for n in range(len(gn)):\n",
    "    ws1.cell(row = 1, column = n+2).value = gn[n]\n",
    "\n",
    "#hitdict[key]=[qstart,qstop,qlen,alen,ids,pos,gaps]    \n",
    "tempgn = []\n",
    "temphn = []\n",
    "for hit in hn:\n",
    "    for gene in gn:\n",
    "        hitps=[]\n",
    "        for item in hitdict:\n",
    "            if (gene in item) and (hit in item):\n",
    "                #if %ID < 90%, ignore. O157 is very homogenous, high ID cutoff\n",
    "                if (int(hitdict[item][4])/int(hitdict[item][3]))<.95:\n",
    "                    continue\n",
    "                qlen = int(hitdict[item][2])\n",
    "                hitps.append((int(hitdict[item][0]),int(hitdict[item][1])))\n",
    "        hitpss = sorted(hitps, key = lambda x: x[0])\n",
    "        for i in range(1, len(hitpss)):\n",
    "            if hitpss[i][0]<hitpss[i-1][1]:\n",
    "                hitpss[i]=(hitpss[i-1][0],hitpss[i][1])\n",
    "                hitpss[i-1]=(0,0)\n",
    "                continue\n",
    "        if (0,0) in hitpss:\n",
    "            for i in range(hitpss.count((0,0))):\n",
    "                hitpss.remove((0,0))\n",
    "\n",
    "        for i in range(1, len(hitpss)):\n",
    "            if hitpss[i][0]<hitpss[i-1][1]:\n",
    "                print('Incomplete trimming')\n",
    "                continue\n",
    "\n",
    "        lens = [(i[1]-i[0]+1) for i in hitpss]\n",
    "        slens = sum(lens)\n",
    "        if (slens/qlen) >= 0.6:\n",
    "            ws1.cell(row = hn.index(hit)+2, column = gn.index(gene)+2).fill = fillyes\n",
    "        else:\n",
    "            ws1.cell(row = hn.index(hit)+2, column = gn.index(gene)+2).fill = fillno\n",
    "        if gene == 'pSS17':\n",
    "            ws1.cell(row = hn.index(hit)+2, column = gn.index(gene)+2).value = (slens/qlen)\n",
    "            \n",
    "\n",
    "wb.save('pSS17_Check.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
